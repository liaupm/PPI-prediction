{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c6dbe3f-1b78-4ee4-b381-2758f2d841e0",
   "metadata": {},
   "source": [
    "Prueba para ver si la función de agregación de atención que tengo se puede estabilizar de forma similar a la softmax:\n",
    "\n",
    "softmax(x) = softmax(x+c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d796b201-2820-43d3-8e0f-a6fc404fb7bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e0392d8c-f814-4761-884f-52b96bac5159",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.randn(3, 10, 2, 10)\n",
    "exp_a = torch.exp(a)\n",
    "\n",
    "alpha = torch.einsum(\"blnk->bl\",exp_a) / torch.einsum(\"blnk->b\", exp_a).unsqueeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b2118951-22e5-40ab-a0a4-f47e80f20de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "a2 = a - torch.max(a)\n",
    "exp_a2 = torch.exp(a2)\n",
    "\n",
    "alpha2= torch.einsum(\"blnk->bl\",exp_a2) / torch.einsum(\"blnk->b\", exp_a2).unsqueeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5539a796-4061-4aed-ad97-94c177eeff76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1250, 0.1082, 0.1510, 0.0761, 0.0732, 0.1004, 0.0717, 0.1019, 0.1194,\n",
       "         0.0731],\n",
       "        [0.0576, 0.1066, 0.0906, 0.0674, 0.0956, 0.1619, 0.0945, 0.0850, 0.1510,\n",
       "         0.0898],\n",
       "        [0.1252, 0.1230, 0.0788, 0.0957, 0.0952, 0.0783, 0.0845, 0.1018, 0.0824,\n",
       "         0.1351]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b5e894d8-378d-4260-a130-33c8764f7553",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1250, 0.1082, 0.1510, 0.0761, 0.0732, 0.1004, 0.0717, 0.1019, 0.1194,\n",
       "         0.0731],\n",
       "        [0.0576, 0.1066, 0.0906, 0.0674, 0.0956, 0.1619, 0.0945, 0.0850, 0.1510,\n",
       "         0.0898],\n",
       "        [0.1252, 0.1230, 0.0788, 0.0957, 0.0952, 0.0783, 0.0845, 0.1018, 0.0824,\n",
       "         0.1351]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9946a69-7123-4936-ad5e-cfe5bc77fd84",
   "metadata": {},
   "source": [
    "¡Al parecer sí funciona! Y debería ser numéricamente estable.\n",
    "\n",
    "Razonamiento de por qué funciona:\n",
    "\n",
    "La función de agregación se define como:\n",
    "$$\n",
    "f(A) = \\frac{\\sum_{n,k}{\\exp(A_{blnk})}}{\\sum_{l,n,k}{\\exp(A_{blnk})}}\n",
    "$$\n",
    "\n",
    "Si añadimos una constante a todo A:\n",
    "$$\n",
    "\\begin{align*}\n",
    "f(A + c) &= \\frac{\\sum_{n,k} \\exp(A_{blnk} + c)}{\\sum_{l,n,k} \\exp(A_{blnk} + c)} \\\\\n",
    "        &= \\frac{\\exp(c) \\sum_{n,k} \\exp(A_{blnk})}{\\exp(c) \\sum_{l,n,k} \\exp(A_{blnk})}\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "¿Lo hace numéricamente más estable?\n",
    "\n",
    "1. Garantiza que ningún número es positivo, por lo que no puede haber overflow en ninguna exponenciación (se evitan inf que pueden llevar a NaN si se divide por ellos).\n",
    "2. Otro problema que puede haber es que haya un underflow de todas las exponenciaciones (lo que haría el denominador cero). En el softmax, que restamos el vector por el valor máximo, sabemos que una de las exponenciaciones es 1, por lo que el denominador no es 0. Sin embargo, en este caso estamos restando el valor máximo de toda la matriz, pero normalizando independientemente en la dimensión de batch. Por tanto, solo tenemos garantizado que uno de los elementos del vector sea distinto de cero.\n",
    "\n",
    "Vamos a probar a ver si se puede restar numeros diferentes a cada row de batch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5af09da9-0422-4b77-baa7-425a7ebe5e08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1386, 0.1294, 0.0935, 0.0642, 0.1184, 0.0913, 0.0531, 0.1075, 0.1108,\n",
       "         0.0933],\n",
       "        [0.1006, 0.1002, 0.1890, 0.0845, 0.0983, 0.0784, 0.1287, 0.0706, 0.0684,\n",
       "         0.0813],\n",
       "        [0.0962, 0.1147, 0.0882, 0.0938, 0.0872, 0.0986, 0.1282, 0.0795, 0.1139,\n",
       "         0.0997]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.randn(3, 10, 2, 10)\n",
    "exp_a = torch.exp(a)\n",
    "\n",
    "alpha = torch.einsum(\"blnk->bl\",exp_a) / torch.einsum(\"blnk->b\", exp_a).unsqueeze(-1)\n",
    "alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e8e18dae-d7af-4a32-90c4-ed3511c5ccd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1386, 0.1294, 0.0935, 0.0642, 0.1184, 0.0913, 0.0531, 0.1075, 0.1108,\n",
       "         0.0933],\n",
       "        [0.1006, 0.1002, 0.1890, 0.0845, 0.0983, 0.0784, 0.1287, 0.0706, 0.0684,\n",
       "         0.0813],\n",
       "        [0.0962, 0.1147, 0.0882, 0.0938, 0.0872, 0.0986, 0.1282, 0.0795, 0.1139,\n",
       "         0.0997]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a2 = a.view(3, 10, 20)\n",
    "a2 = a2 - a2.view(3, -1).max(dim=1, keepdim=True).values.unsqueeze(-1)#torch.max(a2, dim=-1, keepdim=True).values\n",
    "exp_a2 = torch.exp(a2)\n",
    "\n",
    "alpha2= torch.einsum(\"bln->bl\",exp_a2) / torch.einsum(\"bln->b\", exp_a2).unsqueeze(-1)\n",
    "alpha2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e876d5d-a334-4397-98a9-9587bb36a045",
   "metadata": {},
   "source": [
    "¡Conseguido! Lo que hago es restar el máximo para cada ejemplo de batch independientemente. De esta forma se asegura que la matriz a2 es totalmente negativa y además, hay al menos un cero en cada batch, con lo que al aplicar la exponenciación y sumar, el denominador nunca debería poder ser cero.\n",
    "\n",
    "A continuación comprobación de la estabilidad:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b0a50a69-73a0-480d-a8b2-e61cd04ff09c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fagg(A):\n",
    "    exp_A = torch.exp(A)\n",
    "    \n",
    "    alpha = torch.einsum(\"blnk->bl\",exp_A) / torch.einsum(\"blnk->b\", exp_A).unsqueeze(-1)\n",
    "    return alpha\n",
    "\n",
    "def fagg_stable(A):\n",
    "    B, L, N, H = A.size()\n",
    "    A = A.view(B, L, N*H)\n",
    "    A = A - A.view(B, -1).max(dim=1, keepdim=True).values.unsqueeze(-1)\n",
    "    exp_A = torch.exp(A)\n",
    "    \n",
    "    alpha = torch.einsum(\"bln->bl\",exp_A) / torch.einsum(\"bln->b\", exp_A).unsqueeze(-1)\n",
    "    return alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f80d1b6d-a42a-4f2c-9c81-50137d7011e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(True)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = torch.randn(3, 4, 2, 3)\n",
    "(fagg(A) == fagg_stable(A)).all()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dd264df-d671-42a9-b8b6-2974a285c4d9",
   "metadata": {},
   "source": [
    "Actuación frente a infinitos (exp(88.723) > 3.4e38, el mayor valor posible para un float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "d4b7870c-c25f-452e-a662-b481fc41d095",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = torch.rand(3, 4, 2, 3)\n",
    "A[0, 0, 0, 0] = 88.723\n",
    "A[0, 1, 0, 0] = 88.723\n",
    "A[1, 0, 0, 0] = 88.723\n",
    "A[1, 3, 0, 0] = 88.723\n",
    "A[2, 0, 0, 0] = 88.723\n",
    "A[2, 3, 0, 0] = 88.723"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "2f561619-82e9-41bb-a957-031ff1512667",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[nan, nan, 0., 0.],\n",
       "        [nan, 0., 0., nan],\n",
       "        [nan, 0., 0., nan]])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fagg(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "834d6042-97c7-4982-a805-f020a750129a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5.0000e-01, 5.0000e-01, 1.4145e-38, 1.7592e-38],\n",
       "        [5.0000e-01, 1.4661e-38, 1.3485e-38, 5.0000e-01],\n",
       "        [5.0000e-01, 1.3178e-38, 1.3522e-38, 5.0000e-01]])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fagg_stable(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55a6e337-d8fd-4620-8c7a-413170659f65",
   "metadata": {},
   "source": [
    "faggstable funciona correctamente, y además las filas suman 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "f33f892a-a5bd-4e6d-a858-9c3ab01249c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.exp(torch.tensor([-110], dtype=torch.float32))\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be1f3430-decf-4349-98ce-0fa267b87547",
   "metadata": {},
   "source": [
    "Con -110 ya es suficiente para obtener un cero. El problema de estabilidad que puede ocurrir es qeu todos los números sean demasiado pequeños y entonces el denominador sume cero. Vamos a ver si a fagg_stable le afecta esto:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "c416a24b-d957-4d78-807f-18cf61ec3aee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[nan, nan, nan, nan],\n",
       "        [nan, nan, nan, nan],\n",
       "        [nan, nan, nan, nan]])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = torch.rand(3, 4, 2, 3) - 110\n",
    "fagg(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "ec103c99-3ff3-42d8-97dd-d4fce27e719d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3141, 0.2303, 0.2318, 0.2238],\n",
       "        [0.2854, 0.2514, 0.2538, 0.2094],\n",
       "        [0.2426, 0.2289, 0.2834, 0.2450]])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fagg_stable(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "b2fc0bec-09c5-4941-aa12-a7976d252bd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0000, 1.0000, 1.0000])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fagg_stable(A).sum(dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b5f8d18-9a4c-46e7-af4f-52d58aac2463",
   "metadata": {},
   "source": [
    "Como se puede apreciar, no se ve afectado, al contrario que fagg sin estabilizar. Esto también puede ocurrir si los pesos son muy grandes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "6e9fceea-2bfc-4c1f-a922-0f7de8291e91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[nan, nan, nan, nan],\n",
       "        [nan, nan, nan, nan],\n",
       "        [nan, nan, nan, nan]])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = torch.rand(3, 4, 2, 3) + 110\n",
    "fagg(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "59784c79-efaa-46f7-9c66-a888c46eb32e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2139, 0.1904, 0.3202, 0.2755],\n",
       "        [0.2562, 0.2402, 0.2404, 0.2632],\n",
       "        [0.2385, 0.3024, 0.2321, 0.2270]])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fagg_stable(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "461a110f-0040-40cc-9c69-1cb28e4ad72b",
   "metadata": {},
   "source": [
    "No ocurre si solo unos pocos de los pesos son pequeños"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "933df410-861d-47f9-9e11-8d787cd66435",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0., 0.],\n",
       "        [nan, nan, nan, nan],\n",
       "        [nan, nan, nan, nan]])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = torch.rand(3, 4, 2, 3) - 110\n",
    "A[0,0,0,0] = 0.1\n",
    "fagg(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "92c3f7c6-7a64-4004-9785-8bf890548e42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.2669, 0.2361, 0.2275, 0.2694],\n",
       "        [0.2236, 0.2292, 0.3073, 0.2398]])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fagg_stable(A)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
